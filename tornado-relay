#!/usr/bin/env python

__author__ = 'igor'

import socket
import logging
import struct
import time
import sys
import os
import signal
import functools
import errno
import traceback

import tornado.ioloop
import tornado.process
import tornado.netutil

from tornado.options import options, define, parse_command_line, parse_config_file

from random import choice
from collections import deque
from cPickle import loads, dumps
from cStringIO import StringIO

from carbon.routers import ConsistentHashingRouter, RelayRulesRouter

from tornado import gen

BACKLOG = 100
RECONNECT_INTERVAL = 10
CHUNK_SIZE = 16 * 1024
MAX_LINE_LENGTH = 16 * 1024
MAX_METRIC_NAME_LENGTH = 230

define("line_port", type=int, help="port for line interface", default=2013)
define("pickle_port", type=int, help="port for pickle interface", default=2014)
define("processes", type=int, help="num of parallel processes", default=2)
define("destinations", type=str, help="carbon DESTINATIONS list, comma separated, in format hostname:port:instance",
       default=None)
define("replication", type=int, help="replication factor", default=1)
define("rules", type=str, help="carbon rules file", default=None)
define("instance", type=str, help="instance name", default="a")
define("maxqlen", type=int, help="outpuit queue length", default=100000)
define("config", type=str, help="path to config file", default=None)
define("connpool", type=int, help="# of connections to each destination", default=1)

parse_command_line()
if options.config:
    parse_config_file(options.config)

if not options.destinations:
    print "Can't run without --destinations"
    sys.exit(1)


def mysleep(interval, callback):
    tornado.ioloop.IOLoop.instance().add_timeout(time.time() + interval, callback)


class Connection(object):
    """
    single connection to destination
    """
    __slots__ = ('socket', 'state', 'addr', 'to_send', 'sent', 'to_send_data', 'send_callback')

    DISCONNECTED = 0
    CONNECTED = 1

    def __init__(self, addr):
        self.addr = addr
        self.socket = None
        self.state = Connection.DISCONNECTED
        self.to_send = None
        self.sent = None
        self.to_send_data = None
        self.send_callback = None
        self.start_connection()

    def handle_error(self, err):
        self.socket.close()
        self.state = Connection.DISCONNECTED
        self.to_send = self.sent = None
        logging.info('%s failed to write/connect to %s: %s' % (
            tornado.process.task_id(),
            str(self.addr),
            os.strerror(err) if err else "-"
        ))
        io_loop = tornado.ioloop.IOLoop.instance()
        io_loop.add_timeout(time.time() + RECONNECT_INTERVAL, self.start_connection)

    def event_handler(self, fd, event):
        #print fd, event, self.state
        io_loop = tornado.ioloop.IOLoop.instance()
        if self.state == Connection.DISCONNECTED:
            #logging.info("fd: %s event: %s, self.state: %d" % (str(fd), str(event), self.state))
            if event & io_loop.ERROR:
                err = self.socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)
                io_loop.remove_handler(fd)
                self.socket.close()
                logging.info('%s failed to connect to %s: %s' % (
                    tornado.process.task_id(),
                    str(self.addr),
                    os.strerror(err) if err else "-"
                ))
                io_loop.add_timeout(time.time() + RECONNECT_INTERVAL, self.start_connection)
                return
            if event & io_loop.WRITE:
                self.state = Connection.CONNECTED
                logging.info('%s connected to %s' % (tornado.process.task_id(),
                                                     str(self.addr)))
                io_loop.update_handler(fd, io_loop.READ)
                return
            else:
                logging.error('%s unexpected event %d' % (tornado.process.task_id(),
                                                     event))

        elif self.state == Connection.CONNECTED:
            if event & io_loop.READ:
                #r = self.socket.recv(1500)
                self.state = Connection.DISCONNECTED
                io_loop.remove_handler(fd)
                self.socket.close()
                logging.info('%s error on socket %s, close connection' % (
                    tornado.process.task_id(),
                    str(self.addr)
                ))
                io_loop.add_timeout(time.time() + RECONNECT_INTERVAL, self.start_connection)
                self.to_send = self.sent = None
                cb = self.send_callback
                self.send_callback = None
                if cb is not None:
                    cb()
                return

            if event & io_loop.WRITE:
                logger.debug('write event')
                while self.to_send > 0:
                    try:
                        r = self.socket.send(self.to_send_data[self.sent:self.sent+min(self.to_send, CHUNK_SIZE)])
                        if r <= 0:
                            err = self.socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)
                            self.handle_error(err)
                            break
                        logger.debug("r=%d" % r)
                        self.sent += r
                        self.to_send -= r
                    except socket.error as e:
                        if e.args[0] in (errno.EWOULDBLOCK, errno.EINPROGRESS):
                            return
                        self.state = Connection.DISCONNECTED
                        io_loop.remove_handler(fd)
                        self.socket.close()
                        logging.info('%s error on socket during write %s, close connection' % (
                            tornado.process.task_id(),
                            str(self.addr)
                        ))
                        io_loop.add_timeout(time.time() + RECONNECT_INTERVAL, self.start_connection)
                        self.to_send = self.sent = None
                        cb = self.send_callback
                        self.send_callback = None
                        cb()
                        return

                    except Exception, e:
                        err = self.socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)
                        logger.error('send: %s' % str(e.args[0]))
                        self.handle_error(err)
                        break
                io_loop.update_handler(fd, io_loop.READ)
                self.to_send = None
                self.to_send_data = None
                cb = self.send_callback
                self.send_callback = None
                cb()
                return

        err = self.socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)
        self.handle_error(err)

    def start_connection(self):
        logging.info('%s start connection to %s' % (
            tornado.process.task_id(),
            str(self.addr))
        )
        self.socket = socket.socket()
        self.socket.setblocking(0)
        io_loop = tornado.ioloop.IOLoop.instance()
        handler = functools.partial(self.event_handler)
        try:
            self.socket.connect(self.addr)
            self.state = Connection.CONNECTED
            logging.info('%s connected to %s' % (tornado.process.task_id(), str(self.addr)))
            io_loop.add_handler(self.socket.fileno(), handler, io_loop.READ)
            return
        except socket.error, e:
            if e.args[0] in (errno.EINPROGRESS, errno.EWOULDBLOCK, errno.EAGAIN):
                io_loop.add_handler(self.socket.fileno(), handler, io_loop.WRITE)
                return
            raise

    @gen.engine
    def write(self, data, callback=None):
        io_loop = tornado.ioloop.IOLoop.instance()
        if not self.to_send is None:
            raise
        self.to_send_data = data
        self.to_send = len(data)
        self.sent = 0
        self.send_callback = callback
        io_loop.update_handler(self.socket.fileno(), io_loop.READ|io_loop.WRITE)


class Destination(object):
    __slots__ = ('name', 'addr', 'queue', 'overflows', 'in_transmit', 'connections')

    def __init__(self, n):
        """

        @type self: Destination
        @param n: destination name
        @type n: str
        """
        self.name = n
        self.queue = deque([], options.maxqlen)
        self.overflows = 0
        self.in_transmit = False
        self.addr = (self.name.split(':')[0], int(self.name.split(':')[1]))
        self.connections = [Connection(self.addr) for _ in range(options.connpool)]

        logger.debug(self.name + ' destination created')

    @gen.engine
    def start_send_queue(self, callback=None):
        if self.in_transmit:
            if callback:
                callback()
            return
        self.in_transmit = True
        logger.debug(self.name + ' sending ' + str(self.queue))
        while len(self.queue) > 0:
            available_connections = \
                [c for c in self.connections if c.state == Connection.CONNECTED]
            if len(available_connections) == 0:
                logging.error('no available connections at start_send_queue')
                break
            # start transmission
            data = self.queue.popleft()
            length = len(data)
            header = struct.pack('!L', length)
            connection = choice(available_connections)
            try:
                yield gen.Task(connection.write, header + data)
            # except IOError:
            #     logging.error('IOError writing to %s' % (str(connection.addr)))
            except:
                logging.error('Unexpected exception '+traceback.format_exc())
        self.in_transmit = False
        if callback:
            callback()

    def __str__(self):
        return self.name


@gen.engine
def read_bytes(so, rec, num_bytes, callback):
    """
    read some bytes and return number or None if error
    can return more bytes then requested
    @param so: socket to read from
    @type  so: socket.socket
    @param rec: StringIO to read to
    @type  rec: StringIO
    @param num_bytes: minimum num of bytes to read (can read more)
    @type  num_bytes: int
    @param callback: callback
    """
    io_loop = tornado.ioloop.IOLoop.instance()

    def read_data_or_fail(__so, __callback):
        def handler(hs, fd, event):
            logger.debug('received event %s on fd:%d' % (event, fd))
            io_loop.remove_handler(hs.fileno())
            try:
                socket_data = hs.recv(8192)
            except:
                hs.close()
                __callback((False, None))
                return
            if not socket_data:
                hs.close()
                __callback((False, None))
                return
            else:
                __callback((True, socket_data))
        read_callback = functools.partial(handler, __so)
        io_loop.add_handler(__so.fileno(), read_callback, io_loop.READ)

    rec.seek(0, 2)  # seek to end
    got = 0
    while got < num_bytes:
        r = yield gen.Task(read_data_or_fail, so)
        (s, d) = r
        if not s:
            callback(None)
            return
        rec.write(d)
        got += len(d)
    callback(got)
    return


class LineHandler(object):
    def __init__(self, router, destinations):
        """
        @type router: carbon.routers.ConsistentHashingRouter
        @type destinations: dict
        """
        self.router = router
        self.destinations = destinations

    @gen.engine
    def __call__(self, sock, peer):
        """
        @type sock: socket.socket
        @type peer: str
        """
        logger.debug('line socket accepted from '+str(peer))
        router = self.router
        destinations = self.destinations
        record = StringIO()
        lines = deque()
        while True:
            buff = None
            eol = -1
            while True:
                got_bytes = yield gen.Task(read_bytes, sock, record, 1)
                if got_bytes is None:
                    break
                buff = record.getvalue()
                if len(buff) >= MAX_LINE_LENGTH:
                    #  logger.error('Line is too long, abort reading')
                    break
                eol = buff.find('\n')
                if eol >= 0:
                    break
            if eol < 0:
                break
            while True:
                line = buff[:eol+1]
                lines.append(line)
                logger.debug("received line "+line.strip())
                buff = buff[eol+1:]
                eol = buff.find('\n')
                if eol < 0:
                    tail = buff
                    break

            record = StringIO()
            record.write(tail)
            logger.debug('reading tail '+tail)

            while len(lines):
                line = lines.popleft()
                batches = dict()
                try:
                    split = line.strip().split()
                    data = (split[0], (split[2], split[1]))
                except IndexError:
                    continue
                if len(destinations.keys()) == router.replication_factor:
                    for dest in destinations.keys():
                        batches[dest] = [data]
                else:
                    metric = split[0]
                    for dest in self.router.getDestinations(metric):
                        dest_key = ':'.join(dest)
                        if dest_key in batches:
                            batches[dest_key].append(data)
                        else:
                            batches[dest_key] = [data]
                for key, data in batches.items():
                    destination = self.destinations[key]
                    if len(destination.queue) >= options.maxqlen:
                        destination.overflows += 1
                    destination.queue.append(dumps(data))
                    yield gen.Task(destination.start_send_queue)

        logger.debug('close connection')
        sock.close()
        return


class PickleHandler(object):
    def __init__(self, router, destinations):
        """
        @type router: carbon.routers.ConsistentHashingRouter
        @type destinations: dict
        """
        self.router = router
        self.destinations = destinations

    @gen.engine
    def __call__(self, sock, peer):
        """
        @type sock: socket.socket
        @type peer: str
        """

        def cleanup():
            logger.debug('cleaning up')
            record.close()

        logger.debug('pickle socket accepted from %s' % str(peer))

        record = StringIO()
        record_length = 0
        header_length = struct.calcsize('!L')

        while True:

            if record_length < header_length:
                got_bytes = yield gen.Task(
                    read_bytes, sock, record,
                    header_length-record_length
                )
                if got_bytes is None:
                    break
                record_length += got_bytes

            record.seek(0, 0)  # seek to begin
            header = record.read(header_length)
            message_length = struct.unpack('!L', header)[0]
            record.seek(0, 2)  # seek to end
            logger.debug('got header, message length=%d' % message_length)

            if record_length < header_length + message_length:
                got_bytes = yield gen.Task(
                    read_bytes, sock, record,
                    header_length+message_length-record_length
                )
                if got_bytes is None:
                    break

            record.seek(header_length, 0)
            message = record.read(message_length)
            tail = record.read()
            record = StringIO()
            record.write(tail)
            record_length = len(tail)
            logger.debug('got message')

            # route received message and place in outgoing queue
            router = self.router
            destinations = self.destinations

            # route data to destinations
            batches = dict()
            if False and len(destinations.keys()) == router.replication_factor:
                for dest in destinations.keys():
                    batches[dest] = message
            else:
                for metric, value in loads(message):
                    if len(metric) >= MAX_METRIC_NAME_LENGTH:
                        #  logging.error('too long metric: %s' % metric)
                        continue
                    for dest in self.router.getDestinations(metric):
                        dest_key = ':'.join(dest)
                        if dest_key in batches:
                            batches[dest_key].append((metric, value))
                        else:
                            batches[dest_key] = [(metric, value)]
                for (destination, data) in batches.items():
                    batches[destination] = dumps(data)

            for key, data in batches.items():
                destination = self.destinations[key]
                if len(destination.queue) >= options.maxqlen:
                    destination.overflows += 1
                destination.queue.append(data)
                yield gen.Task(destination.start_send_queue)

            logger.debug('continue reading (current length=%d)' % record_length)

        logger.debug('connection closed')
        cleanup()
        return


def main(opts):
    assert opts.destinations
    assert opts.instance
    line_port = int(opts.line_port)
    pickle_port = int(opts.pickle_port)
    processes = int(opts.processes)
    destinations = opts.destinations.split(',')
    replication_factor = opts.replication

    line_socket = socket.socket()
    line_socket.setblocking(0)
    line_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    line_socket.bind(('0.0.0.0', line_port))
    line_socket.listen(BACKLOG)
    pickle_socket = socket.socket()
    pickle_socket.setblocking(0)
    pickle_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    pickle_socket.bind(('0.0.0.0', pickle_port))
    pickle_socket.listen(BACKLOG)

    tornado.process.fork_processes(processes)

    if options.rules:
        router = RelayRulesRouter(options.rules)
    else:
        router = ConsistentHashingRouter(replication_factor=replication_factor)

    DESTINATIONS = dict()
    # create destinations
    for destination in destinations:
        DESTINATIONS[destination] = Destination(destination)
        router.addDestination(destination.split(':'))

    tornado.netutil.add_accept_handler(line_socket, LineHandler(router, DESTINATIONS))
    tornado.netutil.add_accept_handler(pickle_socket, PickleHandler(router, DESTINATIONS))

    tornado.ioloop.IOLoop.instance().start()


def signal_handler(signum, frame):
    """
    @param signum: int
    @param frame: frame
    """
    tornado.ioloop.IOLoop.instance().stop()


if __name__ == '__main__':
    logger = logging.getLogger()
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGPIPE, signal.SIG_IGN)
    main(options)
